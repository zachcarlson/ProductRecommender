{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f256f67a",
      "metadata": {
        "id": "f256f67a"
      },
      "source": [
        "# Using PySpark to Create an Amazon Review Recommendation System \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd22a959",
      "metadata": {
        "id": "dd22a959"
      },
      "source": [
        "This Jupyter Notebook contains code to create a recommendation system for Amazon user reviews on specific products using PySpark.  It was created as a final project for the class INFO 607: Applied Database Technologies at Drexel University.  The data was downloaded from [here](https://jmcauley.ucsd.edu/data/amazon/).  \n",
        "\n",
        "Additional documentation on this project can be found at the Github repository [here](https://github.com/zachcarlson/ProductRecommender)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5048aca6",
      "metadata": {
        "id": "5048aca6"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1089410",
      "metadata": {
        "id": "b1089410"
      },
      "source": [
        "We recommend running this notebook in Google Colab using a local runtime and your GPU.  Here are [links](https://stackoverflow.com/questions/51002045/how-to-make-jupyter-notebook-to-run-on-gpu) to setting up this configuration:\n",
        "- [Local Runtime](https://research.google.com/colaboratory/local-runtimes.html)\n",
        "- [Utilizing GPU](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
        "\n",
        "Configure your input directory below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ZzpwWEZ5acF",
      "metadata": {
        "id": "3ZzpwWEZ5acF"
      },
      "outputs": [],
      "source": [
        "INPUT_DIRECTORY = \"/content/drive/MyDrive/Grad School/INFO 607/ProductRecommender/data/\" #for google mount\n",
        "# INPUT_DIRECTORY = \"ProductRecommender/data/\" #for jupyter notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebbb3f3b",
      "metadata": {
        "id": "ebbb3f3b"
      },
      "source": [
        "### Google Colab Hosted Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**: Due to the limited resources available for Google Colab's Free Tier, this notebook might not run for you if you are running it in Google Drive using a Hosted Runtime.  We recommend using a Google Colab Local Runtime.  However, if you have Colab Pro/Pro+, this notebook *might* work and you can uncomment the cells below to continue with that particular configuration."
      ],
      "metadata": {
        "id": "ip1AdpV11Bec"
      },
      "id": "ip1AdpV11Bec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df3783e3",
      "metadata": {
        "id": "df3783e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd09c1fc-5815-45df-f217-b0f5e18cfa54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVCannEhoQbi",
        "outputId": "b83a210c-ca75-4109-f010-3e71e684764e"
      },
      "id": "BVCannEhoQbi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 37 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 64.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=7494ebf7b54072e02bc73cb188b3d5e42d3f3ea828180c1ae77d8eb0f9d7b597\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e0Kq2iN512X",
      "metadata": {
        "id": "6e0Kq2iN512X"
      },
      "source": [
        "The cell below may take 1-2 minutes to execute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XZYrDEpm5e7j",
      "metadata": {
        "id": "XZYrDEpm5e7j"
      },
      "outputs": [],
      "source": [
        "%%capture \n",
        "#prevent large printout with %%capture\n",
        "\n",
        "#Download Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "#Install Apache Spark 3.2.1 with Hadoop 3.2, get zipped folder\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "#Unzip folder\n",
        "!tar xvf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "#Install findspark, pyspark 3.2.1\n",
        "!pip install -q findspark\n",
        "!pip install pyspark==3.2.1\n",
        "\n",
        "#Set variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"spark-3.2.1-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d08603",
      "metadata": {
        "id": "28d08603"
      },
      "source": [
        "### Google Colab Local Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03bf38c8",
      "metadata": {
        "id": "03bf38c8"
      },
      "source": [
        "We recommend using a local Jupyter Notebook as it is much faster for a free user, however, it will require some additional configuration.  Follow this tutorial [here](https://changhsinlee.com/install-pyspark-windows-jupyter/).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b3ec07b",
      "metadata": {
        "id": "3b3ec07b"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tUNtTpW65jJR",
      "metadata": {
        "id": "tUNtTpW65jJR"
      },
      "source": [
        "## Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nduYfIam5na_",
      "metadata": {
        "id": "nduYfIam5na_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pyspark.sql.functions as F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e51316b1",
      "metadata": {
        "id": "e51316b1"
      },
      "source": [
        "## Data Acquisition, Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mC2aHr0-6PaF",
      "metadata": {
        "id": "mC2aHr0-6PaF"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87cec9ff",
      "metadata": {
        "id": "87cec9ff"
      },
      "outputs": [],
      "source": [
        "#create SparkSession and SparkContext objects\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = SparkContext.getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sn3IL-tG6VWb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn3IL-tG6VWb",
        "outputId": "dea9bd74-433e-4a14-be30-ee921a202872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+---+----------+\n",
            "|           _c0|       _c1|_c2|       _c3|\n",
            "+--------------+----------+---+----------+\n",
            "|A1EE2E3N7PW666|B000GFDAUG|5.0|1202256000|\n",
            "| AGZ8SM1BGK3CK|B000GFDAUG|5.0|1198195200|\n",
            "|A2VHZ21245KBT7|B000GIOPK2|4.0|1215388800|\n",
            "| ACX8YW2D5EGP6|B000GIOPK2|4.0|1185840000|\n",
            "| A9RNMO9MUSMTJ|B000GIOPK2|2.0|1281052800|\n",
            "+--------------+----------+---+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Import data via file\n",
        "file_path = INPUT_DIRECTORY + \"ratings_Amazon_Instant_Video.csv\"\n",
        "ratings = spark.read.csv(file_path, header=False, inferSchema=True)\n",
        "ratings.show(5)\n",
        "\n",
        "\n",
        "#import data via URL \n",
        "\n",
        "#uncomment cells below to run this method\n",
        "##from pyspark import SparkFiles\n",
        "##url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Amazon_Instant_Video.csv\"\n",
        "##spark.sparkContext.addFile(url)\n",
        "##ratings = spark.read.csv(SparkFiles.get('ratings_Amazon_Instant_Video.csv'), header=False, inferSchema= True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DRKA4hFSkz0",
        "outputId": "7c1baade-3c34-454a-9949-af1db47e323e"
      },
      "id": "5DRKA4hFSkz0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "583933"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing"
      ],
      "metadata": {
        "id": "nXo2hkRO7uHB"
      },
      "id": "nXo2hkRO7uHB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Rename columns**"
      ],
      "metadata": {
        "id": "6vDAyS2L02rB"
      },
      "id": "6vDAyS2L02rB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xa9-VFAt7zx-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa9-VFAt7zx-",
        "outputId": "4faec718-d022-4b44-ee7f-bf5c30264955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+------+----------+\n",
            "|    reviewerID| productID|rating| timestamp|\n",
            "+--------------+----------+------+----------+\n",
            "|A1EE2E3N7PW666|B000GFDAUG|   5.0|1202256000|\n",
            "| AGZ8SM1BGK3CK|B000GFDAUG|   5.0|1198195200|\n",
            "|A2VHZ21245KBT7|B000GIOPK2|   4.0|1215388800|\n",
            "| ACX8YW2D5EGP6|B000GIOPK2|   4.0|1185840000|\n",
            "| A9RNMO9MUSMTJ|B000GIOPK2|   2.0|1281052800|\n",
            "+--------------+----------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ratings = ratings.withColumnRenamed(\"_c0\", \"reviewerID\") \\\n",
        "                  .withColumnRenamed(\"_c1\", \"productID\") \\\n",
        "                  .withColumnRenamed(\"_c2\", \"rating\") \\\n",
        "                  .withColumnRenamed(\"_c3\", \"timestamp\")\n",
        "ratings.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Check datatypes**"
      ],
      "metadata": {
        "id": "dUx-xNCD04-K"
      },
      "id": "dUx-xNCD04-K"
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgSz974N9HLu",
        "outputId": "8571c1c7-6a62-49ac-906d-2806e72775f1"
      },
      "id": "zgSz974N9HLu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- reviewerID: string (nullable = true)\n",
            " |-- productID: string (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need `reviewerID` and `productID` to be integers for the ALS algorithm.  We'll create separate tables for `reviewers` and `products`.  At the end of the pre-processing section, we'll combine the tables."
      ],
      "metadata": {
        "id": "_hFUXEKb9AFK"
      },
      "id": "_hFUXEKb9AFK"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "reviewers = ratings.select(\"reviewerID\").distinct().coalesce(1)\n",
        "reviewers.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIr62vv_9D0f",
        "outputId": "4bdaa171-fbdd-4efa-a5aa-a93d8792486f"
      },
      "id": "DIr62vv_9D0f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|    reviewerID|\n",
            "+--------------+\n",
            "|A3FF40QHATHVK0|\n",
            "|A2OYUAR8I1QT2O|\n",
            "|A28DPR143MALN7|\n",
            "|A1RNJ6Q36443HL|\n",
            "| A2YJL1MX3J4OK|\n",
            "+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviewers = reviewers.withColumn(\"userID\", monotonically_increasing_id()).persist()\n",
        "reviewers.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yzs6NoH-CTQ",
        "outputId": "14c96bae-7aec-4b5e-d2c2-40c2a01dde71"
      },
      "id": "-Yzs6NoH-CTQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------+\n",
            "|    reviewerID|userID|\n",
            "+--------------+------+\n",
            "|A3FF40QHATHVK0|     0|\n",
            "|A2OYUAR8I1QT2O|     1|\n",
            "|A28DPR143MALN7|     2|\n",
            "|A1RNJ6Q36443HL|     3|\n",
            "| A2YJL1MX3J4OK|     4|\n",
            "+--------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "products = ratings.select(\"productID\").distinct().coalesce(1)\n",
        "products = products.withColumn(\"product_ID\", monotonically_increasing_id()).persist()\n",
        "products.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G8xjDyV-Yqm",
        "outputId": "849ec6b0-bef2-47d5-9de6-73bcd20018f4"
      },
      "id": "4G8xjDyV-Yqm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "| productID|product_ID|\n",
            "+----------+----------+\n",
            "|B000OC3FZQ|         0|\n",
            "|B000P41FAA|         1|\n",
            "|B000RKQEQW|         2|\n",
            "|B000TS73MG|         3|\n",
            "|B000U5IH7I|         4|\n",
            "+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **No duplicate ratings**"
      ],
      "metadata": {
        "id": "mTDtLpOe0--T"
      },
      "id": "mTDtLpOe0--T"
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.groupby(\"reviewerID\", \"productID\").count().select(F.max(\"count\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aOE5dlq1E6z",
        "outputId": "d4dc8a76-86ff-4a81-e70e-3e196f4d4bb3"
      },
      "id": "4aOE5dlq1E6z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|max(count)|\n",
            "+----------+\n",
            "|         1|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each user has only one rating per product, thus filtering based on `timestamp` is not needed.  We will keep the timestamp for EDA purposes and to allow for future filtering if the dataset contains multiple ratings for a given user for  a given product."
      ],
      "metadata": {
        "id": "AMDG2mq21N1n"
      },
      "id": "AMDG2mq21N1n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Join tables**"
      ],
      "metadata": {
        "id": "7z12Kz8y1dYA"
      },
      "id": "7z12Kz8y1dYA"
    },
    {
      "cell_type": "code",
      "source": [
        "#Join ratings table with new integer IDs for products and reviewers\n",
        "product_ratings = ratings.join(reviewers, on=\"reviewerID\", how=\"left\")\n",
        "product_ratings = product_ratings.join(products, on=\"productID\", how=\"left\")\n",
        "\n",
        "#select just integer IDs, rating and timestamp\n",
        "product_ratings = product_ratings.select(\"userID\", \"product_ID\", \"rating\", \"timestamp\")\n",
        "product_ratings.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC_VpLN91oRj",
        "outputId": "94d799ca-dd78-485a-85b3-ac1076dfc3a1"
      },
      "id": "sC_VpLN91oRj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+------+----------+\n",
            "|userID|product_ID|rating| timestamp|\n",
            "+------+----------+------+----------+\n",
            "|178680|     21596|   4.0|1402358400|\n",
            "|101878|     21596|   5.0|1392854400|\n",
            "| 84105|     21596|   4.0|1392508800|\n",
            "|195647|     21596|   4.0|1392163200|\n",
            "| 77065|      9656|   5.0|1203897600|\n",
            "+------+----------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rename columns for readability\n",
        "product_ratings = product_ratings.withColumnRenamed(\"userID\", \"reviewerID\")\n",
        "product_ratings = product_ratings.withColumnRenamed(\"product_ID\", \"productID\")\n",
        "product_ratings.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh7p5Zpl2-0k",
        "outputId": "892f563a-0cf2-4f74-d816-cc9f80319db7"
      },
      "id": "wh7p5Zpl2-0k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+------+----------+\n",
            "|reviewerID|productID|rating| timestamp|\n",
            "+----------+---------+------+----------+\n",
            "|    178680|    21596|   4.0|1402358400|\n",
            "|    101878|    21596|   5.0|1392854400|\n",
            "|     84105|    21596|   4.0|1392508800|\n",
            "|    195647|    21596|   4.0|1392163200|\n",
            "|     77065|     9656|   5.0|1203897600|\n",
            "+----------+---------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling dataset"
      ],
      "metadata": {
        "id": "0Q_Uj3pPp1Bt"
      },
      "id": "0Q_Uj3pPp1Bt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FIXME** Might remove. There are 7,824,482 records, so 20% is around 1,564,896 rows. Pyspark sampling method is not accurate, so it might be more or less this number of rows. "
      ],
      "metadata": {
        "id": "QcE6-2nOqdOm"
      },
      "id": "QcE6-2nOqdOm"
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_sample = product_ratings.sample(0.2, seed = 0)\n",
        "# ratings_sample.count()"
      ],
      "metadata": {
        "id": "W1YqESKep0cx"
      },
      "id": "W1YqESKep0cx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b869102f",
      "metadata": {
        "id": "b869102f"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e6d39b",
      "metadata": {
        "id": "38e6d39b"
      },
      "source": [
        "Find reviewers with the most ratings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d45b814",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d45b814",
        "outputId": "9c2ad3de-4069-42f3-8a0b-0a384fd2c227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|reviewerID|count|\n",
            "+----------+-----+\n",
            "|    314359|  277|\n",
            "|    320548|  240|\n",
            "|    384298|  212|\n",
            "|    173088|  142|\n",
            "|    115356|  125|\n",
            "+----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "product_ratings.select(\"reviewerID\", \"productID\", \"rating\")\\\n",
        "        .groupby(\"reviewerID\")\\\n",
        "        .count()\\\n",
        "        .sort(\"count\", ascending = False)\\\n",
        "        .show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cIVvJVai9eEB",
      "metadata": {
        "id": "cIVvJVai9eEB"
      },
      "source": [
        "Find products with the most ratings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IEgKLq4H8vzo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEgKLq4H8vzo",
        "outputId": "f4a81ac2-b5b6-4f11-8aee-49721f04c08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|productID|count|\n",
            "+---------+-----+\n",
            "|      452|12633|\n",
            "|    15400|10938|\n",
            "|     3875|10226|\n",
            "|    23936| 8676|\n",
            "|    20401| 6927|\n",
            "+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "product_ratings.select(\"reviewerID\", \"productID\", \"rating\")\\\n",
        "        .groupby(\"productID\")\\\n",
        "        .count()\\\n",
        "        .sort(\"count\", ascending = False)\\\n",
        "        .show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XUe7ew_wAs3Y",
      "metadata": {
        "id": "XUe7ew_wAs3Y"
      },
      "source": [
        "Count and average ratings for each product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VMYUPMA69uge",
      "metadata": {
        "id": "VMYUPMA69uge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ba5af3-462c-4716-9638-cd33af76c5f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+-------+\n",
            "|productID|Count|Average|\n",
            "+---------+-----+-------+\n",
            "|    13490|   41|    5.0|\n",
            "|     9406|   22|    5.0|\n",
            "|    19381|   20|    5.0|\n",
            "|     4990|   19|    5.0|\n",
            "|    13295|   18|    5.0|\n",
            "+---------+-----+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "avg_ratings = (product_ratings\n",
        "                .select(\"productID\", \"rating\")              # Select Columns\n",
        "                .groupby(\"productID\")                       # Group by productID\n",
        "                .agg(                           \n",
        "                     F.count(\"rating\").alias(\"Count\"),      # Count number of ratings\n",
        "                     F.avg(\"rating\").alias(\"Average\")       # Average ratings for each product\n",
        "                     )\n",
        "                .sort(\"Average\", \"Count\", ascending = [False, False]) # Sort results by average and count\n",
        "            )\n",
        "avg_ratings.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1KsHMVZ0ww0Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KsHMVZ0ww0Q",
        "outputId": "21e52af4-d6d5-43f4-c71b-800a4741c504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+------------------+\n",
            "|productID|Count|           Average|\n",
            "+---------+-----+------------------+\n",
            "|    15484|   49|1.9795918367346939|\n",
            "|    10601|   27| 1.962962962962963|\n",
            "|    14583|   18|1.9444444444444444|\n",
            "|    20019|   15|1.9333333333333333|\n",
            "|    15959|   15|1.9333333333333333|\n",
            "+---------+-----+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Number of distinct products: 23,965.00\n",
            "Number of products with low average (less than 2): 2,124.00\n",
            "% low ratings: 8.86\n"
          ]
        }
      ],
      "source": [
        "low_avg_rating = avg_ratings.filter(avg_ratings.Average < 2)\n",
        "low_avg_rating.show(5)\n",
        "\n",
        "product_num = avg_ratings.select(\"productID\").distinct().count()\n",
        "lar_count = low_avg_rating.count()\n",
        "print(f\"Number of distinct products: {product_num :,.2f}\")\n",
        "print(f\"Number of products with low average (less than 2): {lar_count :,.2f}\")\n",
        "print(f\"% low ratings: {lar_count / product_num * 100 :,.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gXZM8yPDzsfI",
      "metadata": {
        "id": "gXZM8yPDzsfI"
      },
      "source": [
        "The precentage of low rating (less than 2) products is low (8.9%). "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d752082",
      "metadata": {
        "id": "7d752082"
      },
      "source": [
        "## Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7b55cfc",
      "metadata": {
        "id": "a7b55cfc"
      },
      "source": [
        "Now we'll build our ALS algorithm using collaborative filtering:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f090a1d",
      "metadata": {
        "id": "0f090a1d"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "# Initialize ALS with parameters\n",
        "als = ALS(userCol=\"reviewerID\", itemCol=\"productID\", ratingCol=\"rating\",\n",
        "          nonnegative=True, coldStartStrategy=\"drop\", implicitPrefs=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll build the `ParamGridBuilder`:"
      ],
      "metadata": {
        "id": "GJ9WEMnS4tSW"
      },
      "id": "GJ9WEMnS4tSW"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "\n",
        "param_grid = ParamGridBuilder() \\\n",
        "                  .addGrid(als.rank, [5, 20]) \\\n",
        "                  .addGrid(als.maxIter, [5]) \\\n",
        "                  .addGrid(als.regParam, [0.01, 0.05, 1]) \\\n",
        "                  .build()"
      ],
      "metadata": {
        "id": "3b-QOxmq4wLj"
      },
      "id": "3b-QOxmq4wLj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll build our evaluator and use RMSE as the performance metric:"
      ],
      "metadata": {
        "id": "B0PVeoCk4yqi"
      },
      "id": "B0PVeoCk4yqi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b337gxvK5p_k",
      "metadata": {
        "id": "b337gxvK5p_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2296f2d4-aca3-4904-d971-2f841b6bf42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num models to be tested: 6\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Define evaluator\n",
        "reg_eval = RegressionEvaluator(metricName = \"rmse\",\n",
        "                               predictionCol = \"prediction\",\n",
        "                               labelCol = \"rating\")\n",
        "\n",
        "print(f\"Num models to be tested: {len(param_grid)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating `CrossValidator`:"
      ],
      "metadata": {
        "id": "eJZbJUmt5E31"
      },
      "id": "eJZbJUmt5E31"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator\n",
        "\n",
        "cv = CrossValidator(estimator = als, \n",
        "                    estimatorParamMaps= param_grid,\n",
        "                    evaluator = reg_eval,\n",
        "                    numFolds = 5)"
      ],
      "metadata": {
        "id": "ALly1m8u5EX_"
      },
      "id": "ALly1m8u5EX_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can fit our training data:"
      ],
      "metadata": {
        "id": "4YpKEk9V5Ljy"
      },
      "id": "4YpKEk9V5Ljy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampled dataframe"
      ],
      "metadata": {
        "id": "EyKayka3rGrD"
      },
      "id": "EyKayka3rGrD"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Split data into 80% train, 20% test\n",
        "# training_data, test_data = ratings_sample.randomSplit([0.8, 0.2], seed = 0)\n",
        "\n",
        "# # Training model\n",
        "# model = cv.fit(training_data)\n",
        "\n",
        "# # Get best model\n",
        "# best_model = model.bestModel"
      ],
      "metadata": {
        "id": "KGKkg_ZZ4rsS"
      },
      "id": "KGKkg_ZZ4rsS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full dataframe"
      ],
      "metadata": {
        "id": "9qtmIemDrIZF"
      },
      "id": "9qtmIemDrIZF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into 80% train, 20% test\n",
        "training_data, test_data = product_ratings.randomSplit([0.8, 0.2], seed = 0)\n",
        "\n",
        "# Training model\n",
        "model = cv.fit(training_data)\n",
        "\n",
        "# Get best model\n",
        "best_model = model.bestModel"
      ],
      "metadata": {
        "id": "yxnwtsu1rGNx"
      },
      "id": "yxnwtsu1rGNx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(best_model))\n",
        "\n",
        "print(\"\\n**Best Model**\")\n",
        "print(\"  Rank:\", best_model.rank)\n",
        "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
        "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"
      ],
      "metadata": {
        "id": "UDDfb6Jx5epJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81599c1-d340-47aa-c04b-c42cfff3d93a"
      },
      "id": "UDDfb6Jx5epJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.ml.recommendation.ALSModel'>\n",
            "\n",
            "**Best Model**\n",
            "  Rank: 5\n",
            "  MaxIter: 5\n",
            "  RegParam: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can evaluate our model's performance on the test data:"
      ],
      "metadata": {
        "id": "i8aJBpVw5ihQ"
      },
      "id": "i8aJBpVw5ihQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict ratings using trained model\n",
        "predictions = best_model.transform(test_data)\n",
        "predictions.show(5)"
      ],
      "metadata": {
        "id": "_YAAa8rq5CmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9b74c1-3333-45c3-f125-4c99b33e8215"
      },
      "id": "_YAAa8rq5CmM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+------+----------+----------+\n",
            "|reviewerID|productID|rating| timestamp|prediction|\n",
            "+----------+---------+------+----------+----------+\n",
            "|        15|    20782|   5.0|1385251200| 2.5404944|\n",
            "|        15|    22391|   5.0|1385251200|  2.975179|\n",
            "|        22|    16833|   5.0|1383955200| 3.7255514|\n",
            "|        22|    17391|   5.0|1403913600| 3.6304004|\n",
            "|        41|     3875|   5.0|1393372800| 3.2725685|\n",
            "+----------+---------+------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the \"test_predictions\" dataframe\n",
        "RMSE = reg_eval.evaluate(predictions)\n",
        "\n",
        "# Print the RMSE\n",
        "print(RMSE)"
      ],
      "metadata": {
        "id": "KRwQnZX-5rzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b0c491-8be2-4e4e-d52d-c2c9b1ad7773"
      },
      "id": "KRwQnZX-5rzz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7372979997729052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93faad59",
      "metadata": {
        "id": "93faad59"
      },
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EIaEG1KJ9UOZ",
      "metadata": {
        "id": "EIaEG1KJ9UOZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f4f2191",
      "metadata": {
        "id": "4f4f2191"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ProductRecommender.ipynb",
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}